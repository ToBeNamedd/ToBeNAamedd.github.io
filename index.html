<!DOCTYPE html>
<html>
<head>
  <title>To Be Names</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div id="container">
    <h1>The Emotional Life of my Bike</h1>

    <img src="images/bicycle.jpg" alt="Girl in a jacket">

    <div id="abstract">
        
      <h3>Abstract</h3>
      Conversational AI technology has become increasingly popular. The current state-of-the-art models like chatGPT are primarily used for generating plain, informative texts, jokes and writing business emails. We think that it's only a matter of time before chatGPT-like models will be used to assist in social contexts. For instance, how to deal with grief, how to ask your partner to marry you, or how to handle fights with friends. In that way,  AI could become an always-available psychologist, and humans its patients.
      In The Emotional Life of My Bike we reverse these roles. By giving everyday objects the ability to express their emotions, we present AI not as a solution, but as a patient in need. What happens if Siri does not answer my requests in a neutral tone, but is severely depressed? How do visitors reflect on an AI that suffers from an emotional problem? We aim to explore the emerging role human-computer interactions will have on our social lives, and to better understand its implications. And as an extra, it could provide valuable insights into how we handle emotions amongst ourselves. 
    </div>

    <div id="introduction">
      <h2>Introduction</h2> 
      I admire people who express their emotions openly. My closest friends tend to wear their hearts on their sleeves, and I appreciate this quality about them, even if it can be challenging at times. I value their honesty and authenticity, even when they get angry or upset over something seemingly unimportant. While I understand that some individuals may be more reserved in their emotions, I struggle to relate to those who appear completely emotionless. It's hard for me to comprehend how someone can lack the occasional mood swing.
 
      The strange thing is, I have someone with me that is emotionless all the time: Siri. 
      As someone who values emotional expression in others, I find myself questioning why we don't expect the same from our technology. With my background as a MSc AI graduate, I know that it is not unreasonable to expect emotional expression in technology. The emergence of generative models, such as chat-GPT, have showcased this potential. While cars, fridges, washing machines, watches, and bicycles are becoming increasingly intelligent, none of them are designed to exhibit emotions beyond a spectrum of happy to neutral. Given that humans are emotional creatures, would it be unreasonable to extent this capacity to our technological companions as well? 

      In The Emotional Life of My Bike we strive to give objects the emotional depth they deserve. From our cars to our phones to our washing machines, we are constantly enhancing these objects to be more intelligent and responsive.  We aspire for them to match, or even surpass, the cognitive capabilities of the human brain. Whether we are creating equals or successors, emotionality can and perhaps should be an integral component of the smart objects around us. If Siri wants to be my friend, she should have the decency to understand when I am feeling down, and respond accordingly. If my bike knows I have a bad mood in the morning, I want it to show some compassion. And if my washing machine has my favourite shirt in it, a tactful extra spin cycle would be a considerate gesture.
 
      The concept of giving objects the ability to communicate with us on a psychological level may come  across as optimistic. However, I firmly believe that it is not a question if emotional expression will be integrated into smart technology, but rather when. This believe is supported by <a href="https://www.jmir.org/2019/5/e13216/">recent developments in the field of AI </a> . Striking examples of this development are the creation of an AI therapist named <a href="https://www.theguardian.com/sustainable-business/2015/sep/17/ellie-machine-that-can-detect-depression">Ellie</a> and a robot that teaches  <a href="https://www.theguardian.com/society/2021/aug/08/is-robot-therapy-the-future">cognitive behavioral therapy</a>. Another example that signals a shift away from neutral conversations and into psychological involvement is Snapchat's chatbot which presents itself as a close friend and even asks users if they want to <a href="https://nos.nl/artikel/2472026-een-chatbot-die-in-het-echt-wil-afspreken-ook-snapchat-vindt-het-wat-ver-gaan">meet up in the park</a>. 
  
      As we stand on the cusp of a significant change in how AI will be involved in our lives, it is crucial to recognize that its impact goes beyond just the time we spend with it. The way AI and humans are connected on a psychological level is rapidly evolving, and as an artist I donâ€™t want to look away from this development. Rather, I want to look it directly in the eye.  
  
  
      <h2>Execution</h2> 
      The initial concept for the artwork was centered around the idea of creating an emotionally-aware bicycle. As someone who tends to have a morning mood and often skips breakfast, I find myself annoyed by other overly-enthusiastic cyclists I encounter on my morning bike ride. However, seeing someone who shares my grumpiness gives me a sense of comfort. My ideal bicycle would be a very grumpy one.

      To bring this concept to life, we aim to research different ways of giving everyday objects the ability to show their emotions. Our objective is to develop an interactive installation that showcases a variety of everyday objects with emotive qualities. This will include examining the creation of The Depressed Bike and brainstorming ideas for a Cuckoo Clock with a fear of abandonment, as well as other options such as The Fiat Multipla with Split Personality Disorder and an exhibition of Extatic Cutlery.

      We recognize that the term "interactive" does not necessarily imply direct audible communication between the object and the audience. Therefore, the stand-alone objects will have the ability to express their emotions, and the response of the spectators can be considered an interaction in itself. However, we also have the capability of programming the objects for more extensive interactions, should we choose to do so.

      Our focus is to develop objects that reflect a wide range of emotions and can interact with their surroundings in meaningful ways. By exploring the potential of emotional expression in everyday objects, we hope to inspire discussions about the intersection of art, emotion, and technology.

      <h2>About the makers</h2>
      We are Jonas Kouwenhoven and Casper Wortmann.  
      Casper Wortmann is an artist working on the crossover between art and AI. Casper has been involved in the creation of multiple internationally renowned art works. Among these are <a href="https://driesverhoeven.com/project/happiness/">Happiness</a>, an animatronic created by Studio Dries Verhoeven that travels the world to showcase and experience drug use. He also created robotic movements for <a href="https://driesverhoeven.com/project/broeders-verheft-u-ter-vrijheid/">Brothers</a>, worked on an installation that creates <a href="https://www.idfa.nl/en/film/c534c697-b1ba-46c9-bf75-0fbb8b787ac3/oxygen-debt">audio based on the heartbeats of the spectators</a>, and used generative AI to <a href="https://performancetechnologylab.nl/wp-content/uploads/2020/10/Interview-Diederik-Kreike-Herfstatelier-2020.pdf">create stage-design</a>.  In 2018, he co-created the performance <a href="http://www.technologydrivenart.org/styled/styled-32/">Dear Lollipop</a>, the first performance made especially for an audience of phones, not humans. When it comes to coding, his expertise lies in machine learning for NLP and audio. Casper Wortmann has a degree in both Artificial Intelligence (University of Amsterdam) and Performative Arts (Academy of performative arts, Maastricht).. 

      Jonas Kouwenhoven has a passion for both artificial intelligence and generative art. He holds a BSc degree in AI from UVA Amsterdam and is currently finishing his MSc degree in AI at the VU.  Jonas has been exploring the creative possibilities of combining his technical expertise with his artistic vision through his work on generative art. He was involved in numerous projects at Field.io, a global design studio. Throughout these projects he was able to apply his technical expertise in optimising design workflows using machine learning and work on generative AI. Furthermore, Jonas conducted research with researchers from the computational intelligence group at the VU on generative AI, which resulted  in a project that utilized evolutionary algorithms to generate music.


      <h2>Plan</h2>
      We plan to create the work in three phases.

      Phase 1: Technological preparation
      In the first phase, our focus will be on conducting technological research. This will involve several tasks, such as coding in Python, developing and refining an emotional chatbot, and preparing all the necessary components for its deployment. The primary objective is to ensure that everything is in place for stage 2, and can be easily modified on the go if required. 
      
      Phase 2: Artistic research
      During the second phase, we would like to collaborate with students of the Zuyd University. The aim of this stage is to produce multiple prototypes for art installations that express various psychological themes. We hope to work with a diverse group of students from different backgrounds. 
      The course will focus on  interactive media design, and the working method will be rapid prototyping. Each week we will work with the group towards an (interactive) art installation, such as the cuckoos clock with anxiety, or the melancholic bicycle.

      Phase 3: Exhibition / Tour
      In the third phase of the project, our primary focus will be on combining all elements into a final performance. 


      <h2>Schedule</h2>
      <table style="border-collapse:collapse;border-spacing:0" class="tg"><thead><tr><th style="border-color:#000000;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">June 2023</th><th style="background-color:#c0c0c0;border-color:#000000;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Phase 1: Technological preparation</th></tr></thead><tbody><tr><td style="border-color:#000000;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">September - October 2023</td><td style="border-color:#000000;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">Phase 2: Artistic research<br><span style="font-weight:400;font-style:normal;text-decoration:none">In cooperation with Professorship Technology Driven Art</span><br><span style="font-weight:400;font-style:normal;text-decoration:none">And students from Zuyd University, Maastricht</span><br></td></tr><tr><td style="border-color:#000000;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">November 2023 - January 2024</td><td style="background-color:#c0c0c0;border-color:#000000;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal"><span style="font-weight:300;font-style:normal;text-decoration:none">Exhibition / Tour</span></td></tr></tbody></table>
    
    
    </div>
  </div>